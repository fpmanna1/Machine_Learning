{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 7164454,
     "sourceType": "datasetVersion",
     "datasetId": 4138523
    },
    {
     "sourceId": 7651108,
     "sourceType": "datasetVersion",
     "datasetId": 4460357
    }
   ],
   "dockerImageVersionId": 30646,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import of libraries\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import copy\n",
    "\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-24T11:27:21.962186Z",
     "iopub.execute_input": "2024-02-24T11:27:21.963022Z",
     "iopub.status.idle": "2024-02-24T11:27:33.180371Z",
     "shell.execute_reply.started": "2024-02-24T11:27:21.962981Z",
     "shell.execute_reply": "2024-02-24T11:27:33.179595Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "shutil.rmtree('/kaggle/working/weights/vgg13_bn_29CL_full')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-24T11:14:42.251877Z",
     "iopub.execute_input": "2024-02-24T11:14:42.252767Z",
     "iopub.status.idle": "2024-02-24T11:14:42.398753Z",
     "shell.execute_reply.started": "2024-02-24T11:14:42.252730Z",
     "shell.execute_reply": "2024-02-24T11:14:42.397860Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Original training set path definition\n",
    "dataset_path = \"C:/dataset_MC3/TrainingSet\"\n",
    "\n",
    "# Training set path after split\n",
    "train_path = \"C:/new_data/TRAIN\"\n",
    "\n",
    "# Validation set new path definition\n",
    "val_path = \"C:/new_data/VAL\"\n",
    "\n",
    "# Test set new path definition\n",
    "test_path = \"C:/new_data/TEST\"\n",
    "\n",
    "# Create training, validation and test folders if they don't already exist\n",
    "for folder in [train_path, val_path, test_path]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# List of problem's classes\n",
    "classes = os.listdir(dataset_path)\n",
    "\n",
    "# Set percentual\n",
    "train_perc = 0.6\n",
    "val_perc = 0.2\n",
    "test_perc = 0.2\n",
    "random_seed = 42\n",
    "\n",
    "for class_ in classes:\n",
    "    input_folder = os.path.join(dataset_path, class_)\n",
    "    train_output_folder = os.path.join(train_path, class_)\n",
    "    val_output_folder = os.path.join(val_path, class_)\n",
    "    test_output_folder = os.path.join(test_path, class_)\n",
    "\n",
    "    # Create classes subfolders for training,validation and test folders\n",
    "    if not os.path.exists(train_output_folder):\n",
    "        os.makedirs(train_output_folder)\n",
    "    if not os.path.exists(val_output_folder):\n",
    "        os.makedirs(val_output_folder)\n",
    "    if not os.path.exists(test_output_folder):\n",
    "        os.makedirs(test_output_folder)\n",
    "\n",
    "    # Get the list of all files in the input folder\n",
    "    files_list = []\n",
    "\n",
    "    for file in os.listdir(input_folder):\n",
    "        if file.endswith(\".png\"):\n",
    "            files_list.append(file)\n",
    "\n",
    "    # Split in training,validation and test (paths list)\n",
    "    train_files, test_val_files = train_test_split(files_list, test_size=val_perc + test_perc, random_state=random_seed)\n",
    "    val_files, test_files = train_test_split(test_val_files, test_size=test_perc / (val_perc + test_perc),\n",
    "                                             random_state=random_seed)\n",
    "\n",
    "    # Copy in corresponding training, validation and test set folder, given the path\n",
    "    for file in train_files:\n",
    "        src = os.path.join(input_folder, file)\n",
    "        dst = os.path.join(train_path, val_output_folder, file)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    for file in val_files:\n",
    "        src = os.path.join(input_folder, file)\n",
    "        dst = os.path.join(val_path, val_output_folder, file)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    for file in test_files:\n",
    "        src = os.path.join(input_folder, file)\n",
    "        dst = os.path.join(test_path, val_output_folder, file)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "print(\"Training set, validation set and test set created successfully\")\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check Class Distribution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def count_photos_per_class(dataset_path):\n",
    "    \"\"\"\n",
    "    Conta il numero di foto in ciascuna cartella del dataset.\n",
    "\n",
    "    Argomenti:\n",
    "    - dataset_path (str): Il percorso del dataset.\n",
    "\n",
    "    Ritorna:\n",
    "    - num_photos_per_class (dict): Un dizionario contenente il numero di foto in ciascuna cartella, ordinato in ordine alfabetico.\n",
    "    \"\"\"\n",
    "    # Lista di tutte le cartelle nel dataset, ordinate in modo alfabetico\n",
    "    class_folders = sorted([folder for folder in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, folder))])\n",
    "\n",
    "    # Dizionario per memorizzare il numero di foto in ogni cartella\n",
    "    num_photos_per_class = {}\n",
    "\n",
    "    # Iterazione su ogni cartella e conteggio del numero di foto\n",
    "    for class_folder in class_folders:\n",
    "        class_path = os.path.join(dataset_path, class_folder)\n",
    "        num_photos = len(os.listdir(class_path))\n",
    "        num_photos_per_class[class_folder] = num_photos\n",
    "\n",
    "    return num_photos_per_class"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-23T14:03:03.169106Z",
     "iopub.execute_input": "2024-02-23T14:03:03.169454Z",
     "iopub.status.idle": "2024-02-23T14:03:03.176224Z",
     "shell.execute_reply.started": "2024-02-23T14:03:03.169430Z",
     "shell.execute_reply": "2024-02-23T14:03:03.175204Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Utilizzo della funzione per contare il numero di foto in ciascuna cartella\n",
    "train_path = \"/kaggle/input/weatherdataset/TRAIN\"\n",
    "num_photos_per_class_train = count_photos_per_class(train_path)\n",
    "\n",
    "val_path = \"/kaggle/input/weatherdataset/VAL\"\n",
    "num_photos_per_class_val = count_photos_per_class(val_path)\n",
    "\n",
    "test_path = \"/kaggle/input/weatherdataset/TEST\"\n",
    "num_photos_per_class_test = count_photos_per_class(test_path)\n",
    "\n",
    "orig_train_path = \"/kaggle/input/dataset-mc3/TrainingSet\"\n",
    "num_photos_per_class_orig_train = count_photos_per_class(orig_train_path)\n",
    "\n",
    "# Stampare il numero di foto in ogni cartella\n",
    "print(\"TRAIN:\")\n",
    "for class_name, num_photos in num_photos_per_class_train.items():\n",
    "    print(f\"{class_name}: {num_photos} foto\")\n",
    " \n",
    "print(\"VAL:\")\n",
    "for class_name, num_photos in num_photos_per_class_val.items():\n",
    "    print(f\"{class_name}: {num_photos} foto\")\n",
    "\n",
    "print(\"TEST:\")\n",
    "for class_name, num_photos in num_photos_per_class_test.items():\n",
    "    print(f\"{class_name}: {num_photos} foto\")\n",
    "        \n",
    "print(\"ORIGINAL_TRAIN:\")\n",
    "for class_name, num_photos in num_photos_per_class_orig_train.items():\n",
    "    print(f\"{class_name}: {num_photos} foto\")\n",
    "    "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-23T14:03:59.587123Z",
     "iopub.execute_input": "2024-02-23T14:03:59.587932Z",
     "iopub.status.idle": "2024-02-23T14:03:59.652897Z",
     "shell.execute_reply.started": "2024-02-23T14:03:59.587902Z",
     "shell.execute_reply": "2024-02-23T14:03:59.652065Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "TRAIN:\nBR: 502 foto\nCL: 511 foto\nDA: 495 foto\nRA: 510 foto\nSF: 494 foto\nSH: 485 foto\nVAL:\nBR: 167 foto\nCL: 171 foto\nDA: 165 foto\nRA: 170 foto\nSF: 165 foto\nSH: 162 foto\nTEST:\nBR: 168 foto\nCL: 171 foto\nDA: 165 foto\nRA: 171 foto\nSF: 165 foto\nSH: 162 foto\nORIGINAL_TRAIN:\nBR: 837 foto\nCL: 853 foto\nDA: 825 foto\nRA: 851 foto\nSF: 824 foto\nSH: 809 foto\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check Device"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-24T11:05:10.157865Z",
     "iopub.execute_input": "2024-02-24T11:05:10.158827Z",
     "iopub.status.idle": "2024-02-24T11:05:10.246198Z",
     "shell.execute_reply.started": "2024-02-24T11:05:10.158789Z",
     "shell.execute_reply": "2024-02-24T11:05:10.245245Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "2.1.2\nTrue\nTesla T4\ncuda:0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Definition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, transform = None):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.classes_list = sorted(os.listdir(root_dir))\n",
    "\n",
    "        class_to_idx = {}\n",
    "\n",
    "        for i, cls_name in enumerate(self.classes_list):\n",
    "            class_to_idx[cls_name] = i\n",
    "            \n",
    "        class_to_idx['CL'] = 0\n",
    "        class_to_idx['BR'] = 1\n",
    "\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "        self.images = self.load_images()\n",
    "        \n",
    "        \n",
    "    def load_images(self):\n",
    "        images = []\n",
    "        # voglio una lista percorso_immagine - classe di appartenenza\n",
    "        \n",
    "        for cls_name in self.classes_list:\n",
    "            cls_dir = os.path.join(self.root_dir, cls_name)\n",
    "            class_idx = self.class_to_idx[cls_name]\n",
    "            \n",
    "            for img_name in os.listdir(cls_dir):\n",
    "                img_path = os.path.join(cls_dir, img_name) \n",
    "                images.append((img_path, class_idx))\n",
    "        \n",
    "        return images\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx): # deve ritornare la coppia immagine-label\n",
    "        img_path, label = self.images[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "              \n",
    "        return img, label    \n",
    "                                "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-24T11:27:41.420970Z",
     "iopub.execute_input": "2024-02-24T11:27:41.421757Z",
     "iopub.status.idle": "2024-02-24T11:27:41.432361Z",
     "shell.execute_reply.started": "2024-02-24T11:27:41.421723Z",
     "shell.execute_reply": "2024-02-24T11:27:41.431434Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CustomDataset Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = CustomDataset(root_dir = \"/kaggle/input/weatherdataset/TRAIN\", transform = None)\n",
    "\n",
    "print(\"Numero di immagini del dataset : \", len(dataset))\n",
    "\n",
    "img, label = dataset[1]\n",
    "\n",
    "print(\"Dimensione immagine : \",img.size)\n",
    "print(\"Label : \",label)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img, clim = [0,1])\n",
    "\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "#rendere l'esecuzione deterministica\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "folder_path = '/kaggle/input/weatherdataset/TRAIN'\n",
    "num_subdirectories = 0\n",
    "\n",
    "for name in os.listdir(folder_path):\n",
    "    if os.path.isdir(os.path.join(folder_path, name)):\n",
    "        num_subdirectories += 1\n",
    "        \n",
    "print(\"Classes' number of the problem : \", num_subdirectories)\n",
    "\n",
    "learning_rate = 0.0001   \n",
    "batch_size = 16      \n",
    "set_classes_number = num_subdirectories  \n",
    "num_epoch = 20     "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-24T11:27:47.741829Z",
     "iopub.execute_input": "2024-02-24T11:27:47.742587Z",
     "iopub.status.idle": "2024-02-24T11:27:47.763178Z",
     "shell.execute_reply.started": "2024-02-24T11:27:47.742554Z",
     "shell.execute_reply": "2024-02-24T11:27:47.762125Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "Classes' number of the problem :  6\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataloader Definition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_set_path = \"/kaggle/input/weatherdataset/TRAIN\"\n",
    "val_set_path = \"/kaggle/input/weatherdataset/VAL\"\n",
    "test_set_path = \"/kaggle/input/weatherdataset/TEST\"\n",
    "full_dataset_path = \"/kaggle/input/dataset-mc3/TrainingSet\"\n",
    "\n",
    "data_transform_train = transforms.Compose([\n",
    "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_transform_val = transforms.Compose([\n",
    "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_transform_test = transforms.Compose([\n",
    "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_set_path, transform = data_transform_train)\n",
    "val_dataset = CustomDataset(val_set_path, transform = data_transform_val)\n",
    "test_dataset = CustomDataset(test_set_path, transform = data_transform_test)\n",
    "full_dataset = CustomDataset(full_dataset_path, transform = data_transform_train)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers=3, prefetch_factor=3, persistent_workers=True) \n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False, num_workers=3, prefetch_factor=3, persistent_workers=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers=3, prefetch_factor=3, persistent_workers=True)\n",
    "full_dataloader = DataLoader(full_dataset, batch_size = batch_size, shuffle = True, num_workers=3, prefetch_factor=3, persistent_workers=True) "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-24T11:27:50.270755Z",
     "iopub.execute_input": "2024-02-24T11:27:50.271367Z",
     "iopub.status.idle": "2024-02-24T11:27:53.308952Z",
     "shell.execute_reply.started": "2024-02-24T11:27:50.271336Z",
     "shell.execute_reply": "2024-02-24T11:27:53.308104Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Learning Rate Scheduler: Cosine Annealing Warm Restart"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "class CustomCosineAnnealingWarmRestarts(CosineAnnealingWarmRestarts):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_min=0, save_model_callback=None):\n",
    "        self.save_model_callback = save_model_callback\n",
    "        self.counter = 0\n",
    "        super(CustomCosineAnnealingWarmRestarts, self).__init__(optimizer, T_0, T_mult, eta_min)\n",
    "        \n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        super(CustomCosineAnnealingWarmRestarts, self).step(epoch)\n",
    "        # T_cur è un attributo della classe CosineAnnealingWarmRestarts di PyTorch che tiene \n",
    "        # traccia del numero corrente di iterazioni nel ciclo di riscaldamento e raffreddamento.\n",
    "        if self.T_cur == 0 and self.save_model_callback is not None:\n",
    "            self.save_model_callback(self.last_epoch, self.counter)\n",
    "            self.counter += 1\n",
    "\n",
    "            \n",
    "def save_model(epoch, counter): # epoca in cui vengono salvati i pesi + numero modello\n",
    "    folder_path = '/kaggle/working/cosineWeights/'\n",
    "    file_name = f'{counter}_model_weights.pth'\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    print(f\"Saving model state at the end of epoch {epoch}\")\n",
    "    torch.save(model.state_dict(), file_path)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-24T10:04:53.125316Z",
     "iopub.execute_input": "2024-02-24T10:04:53.125785Z",
     "iopub.status.idle": "2024-02-24T10:04:53.133729Z",
     "shell.execute_reply.started": "2024-02-24T10:04:53.125754Z",
     "shell.execute_reply": "2024-02-24T10:04:53.132693Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Function (with Validation Loop)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def train_loop_validation(train_dataloader, val_dataloader, startEpoch, numEpochs, model_conv, criterionCNN, optimizer_conv, scheduler,\n",
    "                          best_acc, best_loss, best_epoca, outputPath):\n",
    "    print(\"Starting train...\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model_conv = DataParallel(model_conv)\n",
    "    \n",
    "    for epochs in range(startEpoch, numEpochs + 1):\n",
    "        since = time.time()\n",
    "        \n",
    "        modelLoss_train = 0.0 \n",
    "        modelAcc_train = 0.0\n",
    "        \n",
    "        model_conv.train()\n",
    "        \n",
    "        totalSize = 0\n",
    "        \n",
    "        for idx, (inputs, labels) in enumerate(tqdm(train_dataloader)):\n",
    "            inputs = inputs.type(torch.FloatTensor).cuda() # single batch pictures\n",
    "            labels = labels.cuda() # corresponding labels\n",
    "            \n",
    "            optimizer_conv.zero_grad() \n",
    "            model_conv.zero_grad()\n",
    "            \n",
    "            y = model_conv(inputs) \n",
    "            \n",
    "            outp, preds = torch.max(y, 1) \n",
    "            \n",
    "            lossCNN = criterionCNN(y, labels) \n",
    "            modelLoss_train += lossCNN.item() * inputs.size(0)\n",
    "            totalSize += inputs.size(0)\n",
    "            modelAcc_train += torch.sum(preds== labels.data).item()\n",
    "        \n",
    "            lossCNN.backward() # calcolo dei gradienti\n",
    "            optimizer_conv.step() # update weights\n",
    "          \n",
    "            \n",
    "         \n",
    "        modelLoss_epoch_train = modelLoss_train/totalSize\n",
    "        modelAcc_epoch_train = modelAcc_train/totalSize\n",
    "        \n",
    "        if (scheduler is not None):\n",
    "            scheduler.step()\n",
    "        #print('Learning Rate Scheduler', scheduler.get_last_lr())\n",
    "        #print('Learning Rate Optimizer,', optimizer_conv.param_groups[0]['lr'])\n",
    "        \n",
    "            \n",
    "        torch.save(model_conv.state_dict(), outputPath + 'train_weights.pth')\n",
    "    \n",
    "        model_conv.eval() \n",
    "        totalSize_val = 0\n",
    "        modelLoss_val = 0.0\n",
    "        modelAcc_val = 0.0 \n",
    "        \n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs = inputs.type(torch.FloatTensor).cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            y = model_conv(inputs)\n",
    "            outp, preds = torch.max(y,1)\n",
    "            lossCNN = criterionCNN(y, labels)\n",
    "            \n",
    "            modelLoss_val += lossCNN.item() * inputs.size(0)\n",
    "            totalSize_val += inputs.size(0)\n",
    "            modelAcc_val += torch.sum(preds == labels.data).item()\n",
    "        \n",
    "        modelLoss_epoch_val = modelLoss_val/totalSize_val\n",
    "        modelAcc_epoch_val = modelAcc_val / totalSize_val\n",
    "        time_elapsed = time.time()-since\n",
    "        \n",
    "        \n",
    "        print('[Epoch %d][TRAIN on %d [Loss: %.4f  ACC: %.4f]][VAL on %d [Loss: %.4f  ACC: %.4f]][TIME: %.0f m %.0f s]'\n",
    "          %(epochs, totalSize, modelLoss_epoch_train, modelAcc_epoch_train, totalSize_val, modelLoss_epoch_val,\n",
    "            modelAcc_epoch_val, time_elapsed // 60, time_elapsed % 60))\n",
    "        \n",
    "        #if epochs == 1 or modelLoss_epoch_val < best_loss:\n",
    "        # salvo i pesi quando l'accuracy sul val aumenta o quando, a parità di acc, scende la loss\n",
    "        if (modelAcc_epoch_val > best_acc) or (modelAcc_epoch_val == best_acc and modelLoss_epoch_val < best_loss) :\n",
    "          print('     .... Saving best weights ....')\n",
    "          best_acc = modelAcc_epoch_val\n",
    "          best_loss = modelLoss_epoch_val\n",
    "          best_epoca = epochs\n",
    "          #salvataggio dei migliori pesi sul validation\n",
    "          torch.save(model_conv.state_dict(), outputPath + 'best_model_weights.pth')\n",
    "\n",
    "        with open(outputPath + 'lossTrain.txt', \"a\") as file_object:\n",
    "          file_object.write(str(modelLoss_epoch_train) +'\\n')\n",
    "\n",
    "        with open(outputPath + 'AccTrain.txt', \"a\") as file_object:\n",
    "          file_object.write(str(modelAcc_epoch_train)+'\\n')\n",
    "\n",
    "        with open(outputPath + 'lossVal.txt', \"a\") as file_object:\n",
    "          file_object.write(str(modelLoss_epoch_val)+'\\n')\n",
    "\n",
    "        with open(outputPath + 'AccVal.txt', \"a\") as file_object:\n",
    "          file_object.write(str(modelAcc_epoch_val)+'\\n')\n",
    "\n",
    "        sio.savemat(outputPath + 'check_point.mat', {'best_acc': best_acc,\n",
    "                                                     'best_loss': best_loss,\n",
    "                                                     'best_epoca': best_epoca,\n",
    "                                                     'last_epoch': epochs})\n",
    "        \n",
    "        \n",
    "    print(\"Ending train...\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-24T11:27:55.506868Z",
     "iopub.execute_input": "2024-02-24T11:27:55.507199Z",
     "iopub.status.idle": "2024-02-24T11:27:55.527307Z",
     "shell.execute_reply.started": "2024-02-24T11:27:55.507174Z",
     "shell.execute_reply": "2024-02-24T11:27:55.526426Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Function (without Validation)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def train_full_dataset(train_dataloader, startEpoch, numEpochs, model_conv, criterionCNN, optimizer_conv, scheduler, best_acc, best_loss, best_epoca, outputPath):\n",
    "    \n",
    "    print(\"Starting train...\")\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model_conv = DataParallel(model_conv)\n",
    "    \n",
    "    for epochs in range(startEpoch, numEpochs + 1):\n",
    "        since = time.time()\n",
    "        \n",
    "        modelLoss_train = 0.0 \n",
    "        modelAcc_train = 0.0\n",
    "        \n",
    "        model_conv.train()\n",
    "        \n",
    "        totalSize = 0\n",
    "        \n",
    "        # for each batch\n",
    "        for idx, (inputs, labels) in enumerate(tqdm(train_dataloader)):\n",
    "            inputs = inputs.type(torch.FloatTensor).cuda() # single batch pictures\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            optimizer_conv.zero_grad() \n",
    "            \n",
    "            model_conv.zero_grad()\n",
    "            \n",
    "            y = model_conv(inputs)\n",
    "            outp, preds = torch.max(y, 1)\n",
    "            \n",
    "            lossCNN = criterionCNN(y, labels)\n",
    "            \n",
    "            lossCNN.backward()\n",
    "            optimizer_conv.step() \n",
    "            \n",
    "            modelLoss_train += lossCNN.item() * inputs.size(0)\n",
    "            totalSize += inputs.size(0)\n",
    "            modelAcc_train += torch.sum(preds == labels.data).item()\n",
    "            \n",
    "        modelLoss_epoch_train = modelLoss_train / totalSize\n",
    "        modelAcc_epoch_train = modelAcc_train / totalSize\n",
    "            \n",
    "        # salvataggio dei pesi ad ogni iterazione -> nel caso si blocchi e vogliamo riprendere il train\n",
    "        torch.save(model_conv.state_dict(), outputPath + 'train_weights.pth')\n",
    "        \n",
    "        time_elapsed = time.time() - since\n",
    "        \n",
    "        scheduler.step()\n",
    "        print('Learning Rate :', scheduler.get_last_lr())\n",
    "        \n",
    "        print('[Epoch %d][TRAIN on %d [Loss: %.4f  ACC: %.4f]][TIME: %.0f m %.0f s]'\n",
    "              % (epochs, totalSize, modelLoss_epoch_train, modelAcc_epoch_train,\n",
    "                 time_elapsed // 60, time_elapsed % 60))\n",
    "        \n",
    "        if (modelAcc_epoch_train > best_acc) or (modelAcc_epoch_train == best_acc and modelLoss_epoch_train < best_loss):\n",
    "            print('     .... Saving best weights ....')\n",
    "            best_acc = modelAcc_epoch_train\n",
    "            best_loss = modelLoss_epoch_train\n",
    "            best_epoca = epochs\n",
    "            # salvataggio dei migliori pesi sul validation\n",
    "            torch.save(model_conv.state_dict(), outputPath + 'best_model_weights.pth')\n",
    "\n",
    "        with open(outputPath + 'lossTrain.txt', \"a\") as file_object:\n",
    "            file_object.write(str(modelLoss_epoch_train) +'\\n')\n",
    "\n",
    "        with open(outputPath + 'AccTrain.txt', \"a\") as file_object:\n",
    "            file_object.write(str(modelAcc_epoch_train)+'\\n')\n",
    "\n",
    "        sio.savemat(outputPath + 'check_point.mat', {'best_acc': best_acc,\n",
    "                                                     'best_loss': best_loss,\n",
    "                                                     'best_epoca': best_epoca,\n",
    "                                                     'last_epoch': epochs})\n",
    "        \n",
    "    print(\"Ending train...\")\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "networkName = 'vgg13_bn'\n",
    "WeightPath = '/kaggle/working/weights/' + networkName + '_29CL_full/'\n",
    "\n",
    "try:\n",
    "    os.makedirs(WeightPath)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model_ft = torchvision.models.vgg13_bn(weights='IMAGENET1K_V1') \n",
    "# change last fully connected layer\n",
    "model_ft.classifier[-1] = nn.Linear(4096, set_classes_number)\n",
    "\n",
    "# set requires_grad=false\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# train fully connected layers\n",
    "for param in model_ft.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0)\n",
    "\n",
    "#model_ft.classifier[-1].apply(init_weights)\n",
    "\n",
    "#print(model_ft)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-24T11:28:05.388817Z",
     "iopub.execute_input": "2024-02-24T11:28:05.389536Z",
     "iopub.status.idle": "2024-02-24T11:28:10.790868Z",
     "shell.execute_reply.started": "2024-02-24T11:28:05.389504Z",
     "shell.execute_reply": "2024-02-24T11:28:10.789801Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "text": "Downloading: \"https://download.pytorch.org/models/vgg13_bn-abd245e5.pth\" to /root/.cache/torch/hub/checkpoints/vgg13_bn-abd245e5.pth\n100%|██████████| 508M/508M [00:03<00:00, 156MB/s]  \n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_conv = model_ft.cuda()  # move model on GPU\n",
    "criterion = nn.CrossEntropyLoss() # loss definition \n",
    "optimizer_conv = optim.Adam(model_conv.classifier.parameters(), lr=learning_rate)  # optimizer definition\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer_conv, step_size=5, gamma=0.1) # scheduler definition\n",
    "\n",
    "#come è stato fissato T_0 = 96?\n",
    "# dataset di training composto da 2997 immagini, batch size = 128, dunque per completare un epoca\n",
    "# ci vogliono circa 24 iterazioni \n",
    "# scelgo di avere un warm restart ogni 4 epoche, quindi moltiplico per 4\n",
    "\n",
    "#scheduler = CustomCosineAnnealingWarmRestarts(optimizer_conv, T_0=96, T_mult=1, eta_min=1e-8, save_model_callback=save_model)\n",
    "\n",
    "# train model\n",
    "startEpoch = 1\n",
    "best_acc = 0\n",
    "best_loss = 0\n",
    "best_epoca = 0\n",
    "\n",
    "train_loop_validation(train_dataloader, val_dataloader, startEpoch, num_epoch, model_conv, criterion, optimizer_conv, scheduler, best_acc, best_loss, best_epoca, WeightPath)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-24T11:28:32.094133Z",
     "iopub.execute_input": "2024-02-24T11:28:32.094850Z",
     "iopub.status.idle": "2024-02-24T12:12:43.563314Z",
     "shell.execute_reply.started": "2024-02-24T11:28:32.094816Z",
     "shell.execute_reply": "2024-02-24T12:12:43.562136Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "lossModel_Train = []\n",
    "lossModel_val = []\n",
    "accModel_Train = []\n",
    "accModel_val = []\n",
    "\n",
    "#WeightPath = 'alexnet/'\n",
    "file = open(WeightPath + 'lossTrain.txt', 'r')\n",
    "Testo = file.readlines()\n",
    "for element in Testo:\n",
    "  lossModel_Train.append(float(element))\n",
    "\n",
    "file = open(WeightPath + 'lossVal.txt', 'r')\n",
    "Testo = file.readlines()\n",
    "for element in Testo:\n",
    "  lossModel_val.append(float(element))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Model: Training Vs Validation Losses\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(list(range(1,len(lossModel_Train)+1)), lossModel_Train, color='r', label=\"Training Loss\")\n",
    "plt.plot(list(range(1, len(lossModel_val)+1)), lossModel_val, color='g', label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(WeightPath + 'LossTrainVal.png')\n",
    "\n",
    "file = open(WeightPath + 'AccTrain.txt', 'r')\n",
    "Testo = file.readlines()\n",
    "for element in Testo:\n",
    "  accModel_Train.append(float(element))\n",
    "\n",
    "file = open(WeightPath + 'AccVal.txt', 'r')\n",
    "Testo = file.readlines()\n",
    "for element in Testo:\n",
    "  accModel_val.append(float(element))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Training Vs Validation Accuracies\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(list(range(1, len(accModel_Train)+1)), accModel_Train, color='r', label=\"Training Accuracy\")\n",
    "plt.plot(list(range(1, len(accModel_val)+1)), accModel_val, color='g', label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(WeightPath + 'AccTrainVal.png')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-24T12:12:45.147047Z",
     "iopub.execute_input": "2024-02-24T12:12:45.147697Z",
     "iopub.status.idle": "2024-02-24T12:12:45.840635Z",
     "shell.execute_reply.started": "2024-02-24T12:12:45.147659Z",
     "shell.execute_reply": "2024-02-24T12:12:45.839743Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model_conv.eval()\n",
    "totalSize_test = 0\n",
    "modelLoss_test = 0.0\n",
    "modelAcc_test = 0.0\n",
    "\n",
    "for inputs, labels in test_dataloader:\n",
    "    inputs = inputs.type(torch.FloatTensor).cuda()\n",
    "    labels = labels.cuda()\n",
    "\n",
    "    y = model_conv(inputs)\n",
    "    outp, preds = torch.max(y, 1)\n",
    "    lossCNN = criterion(y, labels)\n",
    "\n",
    "    modelLoss_test += lossCNN.item() * inputs.size(0)\n",
    "    totalSize_test += inputs.size(0)\n",
    "    modelAcc_test += torch.sum(preds == labels.data).item()\n",
    "\n",
    "modelLoss_epoch_test = modelLoss_test/totalSize_test\n",
    "modelAcc_epoch_test = modelAcc_test/totalSize_test\n",
    "\n",
    "print(f\"Loss: {modelLoss_epoch_test}\")\n",
    "print(f\"Acc: {modelAcc_epoch_test}\")\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Ensemble"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calculation of the average loss and accuracy across the various models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "model_weights_folder = '/kaggle/working/cosineWeights/'\n",
    "model_files = os.listdir(model_weights_folder)\n",
    "\n",
    "for model_file in model_files:\n",
    "    model_path = os.path.join(model_weights_folder, model_file)\n",
    "    \n",
    "    # Carica il modello\n",
    "    model_conv.load_state_dict(torch.load(model_path))\n",
    "    model_conv.cuda() \n",
    "    model_conv.eval()\n",
    "    \n",
    "    totalSize_test = 0\n",
    "    modelLoss_test = 0.0\n",
    "    modelAcc_test = 0.0\n",
    "\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs = inputs.type(torch.FloatTensor).cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        y = model_conv(inputs)\n",
    "        outp, preds = torch.max(y, 1)\n",
    "        lossCNN = criterion(y, labels)\n",
    "\n",
    "        modelLoss_test += lossCNN.item() * inputs.size(0)\n",
    "        totalSize_test += inputs.size(0)\n",
    "        modelAcc_test += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    # Calcola la loss e l'accuracy del modello corrente\n",
    "    modelLoss_epoch_test = modelLoss_test / totalSize_test\n",
    "    modelAcc_epoch_test = modelAcc_test / totalSize_test\n",
    "    \n",
    "    # Aggiungi la loss e l'accuracy alla lista\n",
    "    losses.append(modelLoss_epoch_test)\n",
    "    accuracies.append(modelAcc_epoch_test)\n",
    "\n",
    "ensemble_loss = sum(losses) / len(losses)\n",
    "ensemble_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "print(f\"Ensemble Loss: {ensemble_loss}\")\n",
    "print(f\"Ensemble Accuracy: {ensemble_accuracy}\")\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prediction Example Using Most Voted Class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "final_test_dir = \"/kaggle/input/dataset-mc3/TestSet\"\n",
    "listImage = os.listdir(final_test_dir)\n",
    "classes = ['CL', 'BR', 'DA', 'RA', 'SF', 'SH']\n",
    "\n",
    "model_weights_folder = '/kaggle/working/cosineWeights/'\n",
    "model_files = os.listdir(model_weights_folder)\n",
    "\n",
    "models = []  \n",
    "for model_file in model_files:  \n",
    "\n",
    "    model_conv.load_state_dict(torch.load(model_file))\n",
    "    model_conv = model_conv.to(device)\n",
    "    model_conv.eval()\n",
    "    models.append(model_conv)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for input in listImage:\n",
    "    img = Image.open(os.path.join(final_test_dir, input))\n",
    "    img = data_transform_test(img).to(device)\n",
    "    img = img.unsqueeze_(0)\n",
    "    \n",
    "    individual_predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        outputs = model_conv(img)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        individual_predictions.append(predicted.item())\n",
    "    \n",
    "    final_prediction = max(set(individual_predictions), key=individual_predictions.count)\n",
    "    \n",
    "    predictions.append({'RowID': input.split('.')[0], 'Class': classes[final_prediction]})\n",
    "\n",
    "test_df = pd.DataFrame(predictions)\n",
    "print(test_df)\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Retraining on the whole dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "outputPath = \"/kaggle/working/weights/resnet50/full_training_weights\"\n",
    "\n",
    "startEpoch = 1\n",
    "best_acc = 0\n",
    "best_loss = 0\n",
    "best_epoca = 0\n",
    "\n",
    "train_full_dataset(train_dataloader, startEpoch, numEpochs, model_conv, criterionCNN, optimizer_conv, scheduler, best_acc, best_loss, best_epoca, outputPath)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kaggle Final Submission"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-06T19:43:03.313540Z",
     "iopub.execute_input": "2024-02-06T19:43:03.314266Z",
     "iopub.status.idle": "2024-02-06T19:43:03.319533Z",
     "shell.execute_reply.started": "2024-02-06T19:43:03.314218Z",
     "shell.execute_reply": "2024-02-06T19:43:03.318263Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_conv.load_state_dict(torch.load('/kaggle/working/weights/resnet50/full_training_weights/best_model_weights.pth'))\n",
    "\n",
    "model_conv = model_conv.cuda()\n",
    "model_conv.eval()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "final_test_dir = \"/kaggle/input/dataset-mc3/TestSet\"\n",
    "\n",
    "Test = pd.DataFrame()\n",
    "listImage = os.listdir(final_test_dir)\n",
    "classes = ['CL','BR','DA','RA','SF','SH']\n",
    "\n",
    "for input in listImage:\n",
    "  img = Image.open(\"/kaggle/input/dataset-mc3/TestSet\" + input)\n",
    "  img = data_transform_test(img).to(device)\n",
    "  img = img.unsqueeze_(0)\n",
    "  outputs = model_conv(img)\n",
    "  _, predicted = torch.max(outputs, 1)\n",
    "  Test = Test._append({'RowID': input.split('.')[0],\n",
    "                       'Class': (classes[predicted.item()])},ignore_index=True)\n",
    "\n",
    "print(Test)\n",
    "    "
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
